{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Module 3: Analyzing text content with natural language processing\"\n",
        "subtitle: \"AI-aided content analysis of sustainability communication\"\n",
        "#author: \"nils.holmberg@iko.lu.se\"\n",
        "---\n",
        "\n",
        "## Lesson 3.1: Reading text into dataframes\n",
        "\n",
        "### [lab notebook](3-1-2-computer-lab-notebook.ipynb){target=\"_blank\"}\n",
        "\n",
        "- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg){width=30%}](https://colab.research.google.com/github/cca-cce/osm-cca/blob/main/jnb/3-1-2-computer-lab.ipynb){target=\"_blank\"}\n",
        "\n",
        "### [lab video](video-url.mp4){target=\"_blank\"}\n",
        "\n",
        "### lab text\n",
        "\n",
        "#### Convert PDF to plain text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q pdfminer.six"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "# Directories containing the PDFs\n",
        "directories = ['organization1', 'organization2']\n",
        "directories = ['/content/osm-cca-nlp/res/pdf/preem', '/content/osm-cca-nlp/res/pdf/vattenfall']\n",
        "\n",
        "for directory in directories:\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.pdf'):\n",
        "                pdf_path = os.path.join(root, file)\n",
        "                text_path = os.path.splitext(pdf_path)[0] + '.txt'\n",
        "\n",
        "                try:\n",
        "                    text = extract_text(pdf_path)\n",
        "                    with open(text_path, 'w', encoding='utf-8') as f:\n",
        "                        f.write(text)\n",
        "                    print(f\"Converted {pdf_path} to {text_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to convert {pdf_path}: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Read plain text to Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Directories containing the text files\n",
        "directories = ['organization1', 'organization2']\n",
        "directories = ['/content/osm-cca-nlp/res/pdf/preem', '/content/osm-cca-nlp/res/pdf/vattenfall']\n",
        "\n",
        "data = []\n",
        "text_index = 1\n",
        "\n",
        "# Allowed characters: alphabetic, punctuation, and whitespace\n",
        "allowed_chars = set(string.ascii_letters + string.punctuation + string.whitespace)\n",
        "\n",
        "for directory in directories:\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.txt'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                folder_name = os.path.basename(root)\n",
        "\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    raw_text = f.read()\n",
        "\n",
        "                # Keep only allowed characters\n",
        "                clean_text = ''.join(c for c in raw_text if c in allowed_chars)\n",
        "\n",
        "                # Replace sequences of whitespace with a single space\n",
        "                clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
        "\n",
        "                # Trim leading and trailing whitespace\n",
        "                clean_text = clean_text.strip()\n",
        "\n",
        "                data.append({\n",
        "                    'text_index': text_index,\n",
        "                    'file_path': file_path,\n",
        "                    'folder_name': folder_name,\n",
        "                    'raw_text': raw_text,\n",
        "                    'clean_text': clean_text\n",
        "                })\n",
        "\n",
        "                text_index += 1\n",
        "\n",
        "# Create DataFrame\n",
        "df_texts = pd.DataFrame(data, columns=['text_index', 'file_path', 'folder_name', 'raw_text', 'clean_text'])\n",
        "\n",
        "# Save DataFrame to TSV file\n",
        "df_texts.to_csv('df_texts.tsv', sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_texts.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}