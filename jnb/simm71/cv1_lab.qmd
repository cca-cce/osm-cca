---
jupyter: python3
---

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cca-cce/osm-cca/blob/main/jnb/simm71/cv1_lab.ipynb)

# Research question

**Introduction:**  
How can computer vision techniques be applied to identify and quantify manifest content features in sustainability communication images that are associated with greenwashing, and to what extent do these features differ between companies with inherently unsustainable operations (e.g., Preem) and those focused on renewable energy (e.g., Vattenfall)? Example YouTube videos ([preem](https://www.youtube.com/watch?v=oYgrxXZTAQg), [vattenfall](https://www.youtube.com/watch?v=YIqk0ylo4rI)).

**Proposed Investigation:**  
This study could utilize computer vision methods to test whether specific visual elements—such as the prevalence of green color tones, pixel-level color distributions, or edge-based structural features—are more prominent in Preem's images compared to Vattenfall's. These elements can provide insights into the visual strategies employed in sustainability communication and their potential link to greenwashing.

**Measuring Color Histograms:**  
Color histograms represent the distribution of colors in an image and can be used to quantify the intensity and frequency of green tones. To investigate greenwashing, we can compute histograms for the green channel in RGB color space or use HSV color space to isolate hue values corresponding to green tones. Comparing the mean intensity or proportion of green pixels between Preem and Vattenfall images could reveal whether Preem's visuals disproportionately emphasize green, potentially to create an impression of sustainability. Advanced analysis could include testing for clusters of green tones that mimic natural settings, such as vegetation or foliage.

**Analyzing Edge Information:**  
Edge detection algorithms, such as Sobel or Canny filters, can be used to measure the density and orientation of edges in an image. These features may reflect structural characteristics associated with natural landscapes (e.g., soft, organic edges) versus artificial settings (e.g., hard, linear edges). For example, images with higher edge density and organic contours might aim to evoke associations with nature, a common greenwashing tactic. By quantifying edge features and comparing them across the two companies, we can determine if Preem employs visual structures that suggest sustainability without substantive backing.

**Additional Considerations:**  
- **Feature Correlation:** Correlating color histogram data with edge information can provide deeper insights into the visual composition of images. For instance, a combination of high green intensity and organic edges might indicate a strategic emphasis on naturalistic visuals.
- **Statistical Tests:** Hypothesis testing (e.g., t-tests or ANOVA) can be used to evaluate significant differences in the visual features of images from the two companies.
- **Automated Classification:** Machine learning models trained on labeled datasets could be developed to classify images based on their likelihood of being greenwashed, using color and edge features as predictors.

By applying these methods, the study aims to uncover patterns in visual content that are associated with greenwashing and assess how these strategies differ between organizations with varying levels of inherent sustainability.

# Download multimodal content data

```{python}
#| colab: {base_uri: https://localhost:8080/}
!rm -rf *.zip osm-cca-* 2>/dev/null
!git clone https://github.com/cca-cce/osm-cca-nlp.git
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
# https://drive.google.com/file/d/1qzRGYLpEfdC3Sukag_fszX_jT-Ylpb4W/view?usp=sharing
!rm -rf *.zip 2>/dev/null
!gdown https://drive.google.com/uc?id=1qzRGYLpEfdC3Sukag_fszX_jT-Ylpb4W
!unzip -q *.zip 2>/dev/null
```

# Extract image files from PDFs

```{python}
#| colab: {base_uri: https://localhost:8080/}
!pip install -q pymupdf
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
import fitz  # PyMuPDF
import os

# List of directories
directories = [
    '/content/osm-cca-nlp/res/pdf/preem',
    '/content/osm-cca-nlp/res/pdf/vattenfall'
]

for directory in directories:
    if not os.path.exists(directory):
        print(f"Directory does not exist: {directory}")
        continue

    for filename in os.listdir(directory):
        if filename.lower().endswith('.pdf'):
            pdf_path = os.path.join(directory, filename)
            print(f"Processing PDF: {pdf_path}")

            try:
                doc = fitz.open(pdf_path)
                for page_num in range(len(doc)):
                    page = doc[page_num]
                    for img_index, img in enumerate(page.get_images(full=True)):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        image_ext = base_image["ext"]

                        # Save the image
                        output_prefix = os.path.join(directory, os.path.splitext(filename)[0])
                        output_filename = f"{output_prefix}_page{page_num}_img{img_index}.{image_ext}"
                        with open(output_filename, "wb") as f:
                            f.write(image_bytes)
                        print(f"Saved image: {output_filename}")
            except Exception as e:
                print(f"Failed to process {pdf_path}: {e}")
```

**List and Validate Directories**: A list of directories containing PDF files is defined. The code iterates through each directory, checking if it exists using `os.path.exists`. If a directory is missing, a message is displayed, and the process continues with the next directory. Example: *"Directory does not exist: /content/osm-cca-nlp/res/pdf/preem"*.

**Process PDF Files**: The script iterates through the files in each valid directory, identifying PDFs by checking if the filename ends with `.pdf`. For each PDF file, it constructs the full path and opens the file using the `fitz.open` function. Example: `fitz.open(pdf_path)` initializes the PDF for further processing.

**Extract and Save Images**: For each page in the PDF, the `get_images` method retrieves all embedded images, returning metadata such as the image reference (`xref`). The `extract_image` method extracts the image data, including bytes and file extension. Each extracted image is saved with a filename indicating the page and image index. Example: An image from page 1 with index 0 of `sample.pdf` is saved as `sample_page1_img0.png`.

**Error Handling**: Errors during processing are caught and displayed without stopping the script. This ensures robust processing across multiple directories and files. Example: *"Failed to process /path/to/file.pdf: [error message]"*.

# Read and display images

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 550}
import cv2
from google.colab.patches import cv2_imshow

# Load an image from file
image_path = '/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png'
image = cv2.imread(image_path)

# Check if the image was successfully loaded
if image is not None:
    # Display the image
    cv2_imshow(image)
else:
    print("Error: Unable to load image.")
```

**Load Image Using OpenCV**: The `cv2.imread` function is used to load an image from a specified file path (`image_path`). If the image file exists and is successfully loaded, it is stored as a multi-dimensional array representing pixel data. Example: `image = cv2.imread(image_path)` loads the image for processing.

**Display Image in Google Colab**: The `cv2_imshow` function, provided specifically for Google Colab, is used to display the loaded image directly within the notebook interface. This function is applied to the `image` array, showing the visual content in its original format. Example: `cv2_imshow(image)` displays the loaded image.

**Error Handling for Image Loading**: A conditional check ensures that the image was successfully loaded. If the image is `None` (e.g., the file path is invalid or the image is corrupted), an error message is printed. Example: `print("Error: Unable to load image.")` alerts the user to any issues.

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 367}
import cv2
import matplotlib.pyplot as plt
import seaborn as sns

# Read the image using OpenCV
image_path = '/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png'  # Replace with your image path
image = cv2.imread(image_path)

# Convert the color scheme from BGR to RGB
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Use Seaborn to improve plot aesthetics
sns.set()  # Apply Seaborn styles

# Display the image
plt.imshow(image_rgb)
plt.axis('off')  # Hide the axis
plt.show()
```

**Read Image Using OpenCV**: The `cv2.imread` function reads an image from a specified file path (`image_path`). The loaded image is stored as a multi-dimensional array, with pixel values represented in the BGR (Blue-Green-Red) color format. Example: `image = cv2.imread(image_path)` loads the image for further processing.

**Convert Color Scheme**: The `cv2.cvtColor` function is used to convert the image color format from BGR (default in OpenCV) to RGB, making it compatible with `matplotlib` for proper color representation. Example: `image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)` prepares the image for accurate display.

**Enhance Plot Aesthetics Using Seaborn**: The `sns.set()` function applies Seaborn's default aesthetic styles to the plot, improving visual consistency and readability. Example: `sns.set()` enhances the appearance of the plot by applying subtle design improvements.

**Display the Image Using Matplotlib**: The `plt.imshow` function displays the RGB-converted image. The `plt.axis('off')` call removes axis labels and ticks for a cleaner presentation. Example: `plt.imshow(image_rgb)` renders the image, and `plt.axis('off')` ensures the focus remains on the visual content. The plot is then displayed with `plt.show()`.

# Convert color image to grayscale

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 567}
import cv2
from google.colab.patches import cv2_imshow

# Read the image
image = cv2.imread('/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png')

# Convert the image to grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Save the grayscale image to a PNG file
output_path = '/content/gray_image.png'
cv2.imwrite(output_path, gray_image)
print(f"Grayscale image saved to {output_path}")

# Display the grayscale image in the notebook
cv2_imshow(gray_image)
```

# Get image descriptives

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
import os
import cv2
import pandas as pd

# Paths to the directories containing images
directories = ['osm-cca-nlp/res/pdf/preem', 'osm-cca-nlp/res/pdf/vattenfall']

# Initialize a list to store image data
image_data = []
image_id = 1  # Initialize image ID counter

# Iterate through each directory
for directory in directories:
    if not os.path.exists(directory):
        print(f"Directory does not exist: {directory}")
        continue

    # Iterate through each file in the directory
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Add other image formats if needed
            # Read the image
            img_path = os.path.join(directory, filename)
            img = cv2.imread(img_path)

            if img is None:  # Skip if the image cannot be loaded
                print(f"Unable to read image: {img_path}")
                continue

            # Extract image dimensions and channels
            height, width, channels = img.shape

            # Append the data to the list
            image_data.append({
                'Image_ID': image_id,
                'Folder_Name': os.path.basename(directory),
                'Filename': filename,
                'Width': width,
                'Height': height,
                'Channels': channels
            })

            image_id += 1  # Increment the image ID

# Create a DataFrame from the image data
image_df = pd.DataFrame(image_data)

# Display the DataFrame
image_df.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/}
image_df.shape
```

**Iterate Through Image Directories**: The code initializes a list of directories (`directories`) containing images and iterates through them. It checks if each directory exists using `os.path.exists`, printing a warning if a directory is missing. This ensures only valid directories are processed. Example: *"Directory does not exist: osm-cca-nlp/res/pdf/preem"*.

**Process and Analyze Images**: For each valid directory, the code loops through all files, selecting those with image extensions (e.g., `.png`, `.jpg`, `.jpeg`). Images are loaded using `cv2.imread`, and their dimensions (`height`, `width`) and channel information are extracted from the `shape` attribute. If an image fails to load, an error message is displayed. Example: *"Unable to read image: osm-cca-nlp/res/pdf/preem/image1.png"*.

**Store Image Metadata**: For each successfully loaded image, metadata such as a unique `Image_ID`, the parent directory name (`Folder_Name`), file name (`Filename`), dimensions (`Width` and `Height`), and number of channels (`Channels`) are appended to a list (`image_data`) as a dictionary. Example: *{'Image_ID': 1, 'Folder_Name': 'preem', 'Filename': 'image1.png', 'Width': 1920, 'Height': 1080, 'Channels': 3}*.

**Create and Display DataFrame**: The collected image metadata is converted into a pandas DataFrame (`image_df`). This structured tabular format facilitates analysis and visualization. The DataFrame includes the columns `Image_ID`, `Folder_Name`, `Filename`, `Width`, `Height`, and `Channels`. Example: `image_df.head()` displays the first few rows of the DataFrame.

# Extract image features, color info

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 337}
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Read the image
image = cv2.imread('/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png')

# Calculate color histograms for each channel
hist_r = cv2.calcHist([image], [0], None, [256], [0, 256])
hist_g = cv2.calcHist([image], [1], None, [256], [0, 256])
hist_b = cv2.calcHist([image], [2], None, [256], [0, 256])

# Normalize histograms
hist_r /= hist_r.sum()
hist_g /= hist_g.sum()
hist_b /= hist_b.sum()

# Create subplots for the original image and histograms
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Plot the original image
axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
axes[0].set_title('Original Image')
axes[0].axis('off')

# Plot the color histograms using Seaborn
sns.lineplot(x=np.arange(256), y=hist_r.squeeze(), color='red', ax=axes[1], label='Red')
sns.lineplot(x=np.arange(256), y=hist_g.squeeze(), color='green', ax=axes[1], label='Green')
sns.lineplot(x=np.arange(256), y=hist_b.squeeze(), color='blue', ax=axes[1], label='Blue')
axes[1].set_title('Color Histograms')
axes[1].set_xlabel('Pixel Value')
axes[1].set_ylabel('Frequency')
axes[1].legend()

# Show the plots
plt.tight_layout()
plt.show()
```

**Read and Display the Image**: The code uses `cv2.imread` to load an image from the specified file path. The loaded image is displayed using `plt.imshow` after converting its color format from BGR (default in OpenCV) to RGB for accurate representation in Matplotlib. Example: `axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))` renders the original image.

**Calculate Color Histograms**: The `cv2.calcHist` function computes the color histograms for each channel (Red, Green, and Blue) of the image. Histograms represent the distribution of pixel intensities (0-255) for each color channel. Example: `cv2.calcHist([image], [0], None, [256], [0, 256])` calculates the histogram for the blue channel.

**Normalize Histograms**: Each histogram is normalized by dividing its values by the total sum of pixel intensities in that channel. This step ensures that the histograms represent relative frequency distributions rather than absolute counts. Example: `hist_r /= hist_r.sum()` normalizes the red channel histogram.

**Visualize the Image and Histograms**:  
- **Original Image**: Displayed in the first subplot using Matplotlib, providing a visual reference for the analyzed image. Example: `axes[0].set_title('Original Image')`.
- **Color Histograms**: The second subplot shows line plots for the red, green, and blue histograms, using Seaborn for aesthetic visualization. The x-axis represents pixel intensity values (0-255), and the y-axis represents normalized frequency. Example: `sns.lineplot(x=np.arange(256), y=hist_r.squeeze(), color='red', ax=axes[1], label='Red')`.

**Enhance Visualization**: The plots are styled using Seaborn and include axis labels, titles, and a legend for clear interpretation. The `plt.tight_layout()` ensures that subplots are neatly arranged without overlapping.

This code provides both a visual representation of the image and detailed insights into its color composition, making it useful for analyzing the distribution of color intensities in an image.

# Extract green color channel

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 684}
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Define the image path
image_path = '/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png'

# Read the image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"The image at {image_path} could not be found.")

# Convert the image from BGR (OpenCV format) to RGB
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Extract the green channel
green_channel = image_rgb[:, :, 1]  # Green channel is the second channel (index 1)

# Plot the green channel as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(green_channel, cmap="Greens", cbar=True)
plt.title("Green Channel Heatmap")
plt.axis("off")  # Hide axes for better visualization
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 489}
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Load the image
image_path = '/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png'
image = cv2.imread(image_path)

# Step 2: Convert the image to HSV color space
hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# Step 3: Define the range for green in HSV
lower_green = np.array([35, 50, 50])  # Lower bound of green hue
upper_green = np.array([85, 255, 255])  # Upper bound of green hue

# Step 4: Create a mask for green pixels
mask = cv2.inRange(hsv_image, lower_green, upper_green)

# Step 5: Apply the mask to create a binary image
binary_image = cv2.bitwise_and(image, image, mask=mask)
binary_image = cv2.cvtColor(binary_image, cv2.COLOR_BGR2GRAY)
binary_image[binary_image > 0] = 255  # Convert to binary (white and black)

# Step 6: Count the number of white pixels in the binary image
white_pixel_count = np.sum(binary_image == 255)
print(f"Number of green pixels (white pixels in binary image): {white_pixel_count}")

# Step 7: Display the binary image
plt.figure(figsize=(8, 8))
plt.title("Binary Image with Green Pixels Highlighted")
plt.imshow(binary_image, cmap='gray')
plt.axis('off')
plt.show()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 1000}
import cv2
import numpy as np
import pandas as pd

# Define the green color range in HSV
lower_green = np.array([35, 50, 50])  # Lower bound of green hue
upper_green = np.array([85, 255, 255])  # Upper bound of green hue

# Define a function to count green pixels
def count_green_pixels(image_path):
    # Read the image
    image = cv2.imread(image_path)
    if image is None:
        return 0  # Handle missing images

    # Convert to HSV color space
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Create the mask for green
    mask = cv2.inRange(hsv_image, lower_green, upper_green)

    # Count the number of white pixels (green in binary mask)
    green_pixel_count = np.sum(mask > 0)
    return green_pixel_count

# Iterate over DataFrame rows
green_pixel_counts = []
base_dir = "/content/osm-cca-nlp/res/pdf/"  # Update with your base directory path

for _, row in image_df.iterrows():
    image_path = f"{base_dir}/{row['Folder_Name']}/{row['Filename']}"
    green_pixel_count = count_green_pixels(image_path)
    green_pixel_counts.append(green_pixel_count)

# Add green pixel count to DataFrame
image_df["Green_Pixels"] = green_pixel_counts

# Save the updated DataFrame if needed
image_df
```

# Normalize images by resize

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 1000}
import cv2
import numpy as np
import pandas as pd

# Define the green color range in HSV
lower_green = np.array([35, 50, 50])  # Lower bound of green hue
upper_green = np.array([85, 255, 255])  # Upper bound of green hue

# Define a function to normalize and count green pixels
def normalize_and_count_green_pixels(image_path):
    # Read the image
    image = cv2.imread(image_path)
    if image is None:
        return 0  # Handle missing images

    # Normalize image to 256x256 dimensions
    normalized_image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_AREA)

    # Convert to HSV color space
    hsv_image = cv2.cvtColor(normalized_image, cv2.COLOR_BGR2HSV)

    # Create the mask for green
    mask = cv2.inRange(hsv_image, lower_green, upper_green)

    # Count the number of white pixels (green in binary mask)
    green_pixel_count = np.sum(mask > 0)
    return green_pixel_count

# Iterate over DataFrame rows
green_pixel_counts = []
base_dir = "/content/osm-cca-nlp/res/pdf/"  # Update with your base directory path

for _, row in image_df.iterrows():
    image_path = f"{base_dir}/{row['Folder_Name']}/{row['Filename']}"
    green_pixel_count = normalize_and_count_green_pixels(image_path)
    green_pixel_counts.append(green_pixel_count)

# Add green pixel count to DataFrame
image_df["Green_Pixels"] = green_pixel_counts

# Save the updated DataFrame if needed
normalized_image_df = image_df.copy()

# Optional: Save the normalized DataFrame to a CSV file
normalized_image_df.to_csv("normalized_image_data.csv", index=False)

# Display the updated DataFrame
normalized_image_df
```

# Summarize and visualize results

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 577}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Aggregate mean green pixels by Folder_Name (organization)
aggregated_data = image_df.groupby("Folder_Name")["Green_Pixels"].mean().reset_index()

# Sort by mean Green_Pixels for better visualization
aggregated_data = aggregated_data.sort_values("Green_Pixels", ascending=False)

# Assign hue to x for better compatibility
plt.figure(figsize=(10, 6))
sns.barplot(
    data=aggregated_data,
    x="Folder_Name",
    y="Green_Pixels",
    hue="Folder_Name",
    dodge=False,  # Prevent split bars
    palette="Greens"
)
plt.title("Mean Green Pixels by Organization", fontsize=14)
plt.xlabel("Organization (Folder Name)", fontsize=12)
plt.ylabel("Mean Green Pixels", fontsize=12)
plt.legend([], [], frameon=False)  # Remove legend
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

# Working with video data

```{python}
import os
import subprocess
```

```{python}
videos = {
    "cv-org1-preem": "https://www.youtube.com/watch?v=oYgrxXZTAQg",
    "cv-org2-vattenfall": "https://www.youtube.com/watch?v=YIqk0ylo4rI"
}
```

```{python}
def extract_frames():
    # Common video file formats to search for
    video_formats = [".mp4", ".webm", ".mkv"]

    for dir_name in videos.keys():
        # Find video files with common formats
        video_files = [
            f for f in os.listdir(dir_name)
            if any(f.endswith(ext) for ext in video_formats)
        ]

        # Process each video file in the directory
        for video in video_files:
            input_path = os.path.join(dir_name, video)
            # Save extracted frames in the same directory as the video file
            output_pattern = os.path.join(dir_name, f"frame_{os.path.splitext(video)[0]}_%04d.png")

            try:
                # Use ffmpeg to extract every 100th frame as PNG
                subprocess.run(
                    [
                        "ffmpeg", "-i", input_path,
                        "-vf", "select=not(mod(n\\,100)),setpts=N/FRAME_RATE/TB",
                        output_pattern
                    ],
                    check=True
                )
            except subprocess.CalledProcessError as e:
                print(f"Failed to extract frames from {input_path}.")
                print("Error details:", e.stderr.decode())
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 1000}
import os
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from PIL import Image
from collections import Counter

def extract_color_histogram(image_path):
    """Extract color histogram from an image."""
    image = Image.open(image_path).convert("RGB")
    image_array = np.array(image)
    reshaped = image_array.reshape(-1, 3)
    return reshaped

def cluster_colors(color_data, n_clusters=10):
    """Cluster color data and find dominant colors."""
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(color_data)
    return kmeans.cluster_centers_, Counter(kmeans.labels_)

def rgb_to_hex(color):
    """Convert an RGB color to a hexadecimal string."""
    return "#{:02x}{:02x}{:02x}".format(int(color[0]), int(color[1]), int(color[2]))

def plot_pie_chart(cluster_centers, cluster_sizes, title):
    """Plot a pie chart showing the proportion of colors in a cluster."""
    hex_colors = [rgb_to_hex(center) for center in cluster_centers]
    total = sum(cluster_sizes.values())
    sizes = [cluster_sizes[i] / total for i in range(len(cluster_centers))]

    plt.figure(figsize=(6, 6))
    plt.pie(sizes, labels=hex_colors, colors=hex_colors, autopct="%.1f%%")
    plt.title(title)
    plt.show()

def process_directory(directory, n_clusters=10):
    """Process a directory of images and cluster their colors."""
    all_colors = []
    for file in os.listdir(directory):
        if file.endswith(".png"):
            file_path = os.path.join(directory, file)
            all_colors.append(extract_color_histogram(file_path))

    all_colors = np.vstack(all_colors)  # Combine all colors into one array
    cluster_centers, cluster_sizes = cluster_colors(all_colors, n_clusters)
    return cluster_centers, cluster_sizes

# Directories containing the images
directories = {"cv-org1-preem": "Organization 1", "cv-org2-vattenfall": "Organization 2"}

# Process each directory and plot the pie charts
for dir_name, title in directories.items():
    cluster_centers, cluster_sizes = process_directory(dir_name)
    plot_pie_chart(cluster_centers, cluster_sizes, f"Dominant Colors in {title}")
```

# Extract image features, edge info

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 1000}
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Read the image
image = cv2.imread('/content/osm-cca-nlp/res/pdf/preem/production-of-renewable-diesel-synsat-project-preem_page5_img0.png', cv2.IMREAD_GRAYSCALE)

# Define edge detection settings
edge_detection_settings = [
    ('Canny', cv2.Canny(image, 50, 150)),
#    ('Laplacian', cv2.Laplacian(image, cv2.CV_64F)),
    ('Sobel_X', cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)),
    ('Sobel_Y', cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5))
]

# Iterate through edge detection settings
for setting_name, edges in edge_detection_settings:
    # Convert the edges to binary (keeping them in 0-255 range)
    edges_binary = np.where(edges > 0, 255, 0).astype(np.uint8)

    # Count the number of white edge pixels
    white_pixel_count = cv2.countNonZero(edges_binary)

    # Concatenate the original image and binary edge image horizontally
    concatenated_image = np.hstack((image, edges_binary))

    # Display the concatenated image using cv2_imshow
    print(f'Edge Detection Algorithm: {setting_name}')
    cv2_imshow(concatenated_image)
    print(f'Number of white edge pixels: {white_pixel_count}\n')

    # Save the concatenated image with the specified filename prefix
    filename = f'edges_{setting_name}.jpg'
    cv2.imwrite(filename, concatenated_image)

    print(f'Saved as {filename}\n')
```

**Read the Image in Grayscale**: The `cv2.imread` function reads the image file specified in the path and loads it in grayscale mode using the `cv2.IMREAD_GRAYSCALE` flag. This simplifies processing by reducing the image to intensity values (0-255) without color channels. Example: `image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)`.

**Apply Edge Detection Techniques**: The script defines a list of edge detection settings, where each method (e.g., `Canny`, `Sobel_X`, `Sobel_Y`) is applied to the grayscale image. These algorithms detect changes in intensity values, highlighting edges in the image:
- **`Canny`**: Applies the Canny edge detection algorithm with thresholds of 50 and 150.
- **`Sobel_X`**: Detects edges in the horizontal direction using the Sobel operator.
- **`Sobel_Y`**: Detects edges in the vertical direction using the Sobel operator.

**Convert Edges to Binary**: Each edge-detected image is converted to a binary format by mapping all positive intensity values to 255 (white) and keeping zero values as 0 (black). This ensures consistency for edge visualization. Example: `edges_binary = np.where(edges > 0, 255, 0).astype(np.uint8)`.

**Count White Edge Pixels**: The number of white pixels (representing detected edges) in the binary edge image is counted using `cv2.countNonZero`. This provides a quantitative measure of edge density for each algorithm. Example: `white_pixel_count = cv2.countNonZero(edges_binary)`.

**Display Concatenated Images**: The original grayscale image and its binary edge-detected counterpart are horizontally concatenated using `np.hstack`. This side-by-side comparison is displayed using `cv2_imshow` in Google Colab for visual analysis. Example: `cv2_imshow(concatenated_image)`.

**Save Processed Images**: Each concatenated image is saved as a file with a prefix corresponding to the edge detection algorithm used. The file is saved in the current working directory. Example: `cv2.imwrite(f'edges_{setting_name}.jpg', concatenated_image)`.

**Output Algorithm Details**: The name of the edge detection algorithm, the number of white edge pixels, and the saved file name are printed to provide a clear record of the results for each method.

This code allows for the visual and quantitative evaluation of different edge detection algorithms, helping to compare their effectiveness in highlighting edges in the given grayscale image.


